{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Files\n",
    "ramp = pd.read_csv(r\"C:\\Users\\agarbier\\Downloads\\D12_RAMP_20250602.csv\")\n",
    "intx = pd.read_csv(r\"C:\\Users\\agarbier\\Downloads\\D12_INTX_20250602.csv\")\n",
    "hwy = pd.read_csv(r\"C:\\Users\\agarbier\\Downloads\\D12_HWY_20250604.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Network Components\n",
    "# Create function that adds score as column based on field character\n",
    "# Repeat for ramp, intersection, and highway\n",
    "# Sum for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Freeway', 'Conventional', 'Expressway', nan], dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hwy['THY_HIGHWAY_ACCESS_CODE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_add(df, type, name, var1, input1, var2, input2, var3, input3, value):\n",
    "    df[name] = 0\n",
    "    if type in ['intersection', 'ramp']:\n",
    "        df[name][(df[var1].isin(input1)) & (df[var2].isin(input2)) & (df[var3].isin(input3))] = value\n",
    "    elif type == 'separated':\n",
    "        df[name][(df['THY_HIGHWAY_ACCESS_CODE'].isin(['Freeway','Expressway'])) & (df[var1].isin(input1)) & (df[var2].isin(input2)) & (df[var3].isin(input3))] = value\n",
    "    elif type == 'atgrage':\n",
    "        df[name][(df['THY_HIGHWAY_ACCESS_CODE'].isin(['Freeway','Expressway']) == -1) & (df[var1].isin(input1)) & (df[var2].isin(input2)) & (df[var3].isin(input3))] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv that includes reference to name, variable, and inputs for filtering and value for when present\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_add(intx, 'intersection', \"calc1\", \"INX_DESIGN_CODE\",['Tee'],\"INX_MAIN_LEFT_CHANNEL_CODE\",[\"Painted Channelization\"],\"INX_MAIN_LANES_AMT\",[1,2,3],5)\n",
    "score_add(intx, 'intersection', \"calc2\", \"INX_DESIGN_CODE\",['Four-Legged'],\"INX_MAIN_LEFT_CHANNEL_CODE\",[\"Painted Channelization\"],\"INX_MAIN_LANES_AMT\",[1,2,3],2)\n",
    "score_add(intx, 'intersection', \"calc3\", \"INX_DESIGN_CODE\",['Tee'],\"INX_MAIN_LEFT_CHANNEL_CODE\",[\"Painted Channelization\"],\"INX_MAIN_SIGNAL_MAST_ARM_IND\",['Y'],1)\n",
    "\n",
    "intx['intx_points'] = intx[[\"calc1\",\"calc2\",\"calc3\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_add(ramp, 'ramp', \"calc1\", \"RAM_DESIGN_DESC\",['Direct or Semi-direct Connector (Right)'],\"RAM_HIGHWAY_GROUP\",[\"Divided Highway\"],\"RAM_HIGHWAY_GROUP\",[\"Divided Highway\"],1)\n",
    "score_add(ramp, 'ramp', \"calc2\", \"RAM_ON_OFF_CODE\",['OFF'],\"RAM_HIGHWAY_GROUP\",[\"Divided Highway\"],\"RAM_HIGHWAY_GROUP\",[\"Divided Highway\"],2)\n",
    "score_add(ramp, 'ramp', \"calc3\", \"RAM_ON_OFF_CODE\",['ON'],\"RAM_HIGHWAY_GROUP\",[\"Divided Highway\"],\"RAM_HIGHWAY_GROUP\",[\"Divided Highway\"],10)\n",
    "\n",
    "ramp['ramp_points'] = ramp[[\"calc1\",\"calc2\",\"calc3\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_add(hwy, 'separated', \"calc1\", \"THY_POPULATION_CODE\",['Urbanized'],\"THY_TERRAIN_CODE\",['Flat', 'Rolling'],\"THY_TERRAIN_CODE\",['Flat', 'Rolling'],1)\n",
    "score_add(hwy, 'separated', \"calc2\", \"THY_POPULATION_CODE\",['Urbanized'],\"THY_TERRAIN_CODE\",['Mountainous'],\"THY_TERRAIN_CODE\",['Mountainous'],2)\n",
    "score_add(hwy, 'atgrage', \"calc3\", \"THY_POPULATION_CODE\",['Rural'],\"THY_TERRAIN_CODE\",['Mountainous'],\"THY_TERRAIN_CODE\",['Mountainous'],10)\n",
    "\n",
    "hwy['road_points'] = hwy[[\"calc1\",\"calc2\",\"calc3\"]].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sliding window to give raw RTE BM EM\n",
    "# Merge windows with scored segments\n",
    "# Add points associated with intersections and ramps\n",
    "# Percent add based on segment overlap for roadway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwy_sort = hwy[['PMRouteID_Fix','begPM_Fix','endPM_Fix']].sort_values(by = ['PMRouteID_Fix','begPM_Fix'],ascending = True)\n",
    "hwy_sort['prior_endPM'] = hwy_sort['endPM_Fix'].shift(1)\n",
    "hwy_sort['prior_RID'] = hwy_sort['PMRouteID_Fix'].shift(1)\n",
    "hwy_sort['merge'] = 0\n",
    "hwy_sort['merge'][(hwy_sort['prior_endPM'] == hwy_sort['begPM_Fix']) & (hwy_sort['prior_RID'] == hwy_sort['PMRouteID_Fix'])] = 1\n",
    "\n",
    "unique_id = 0\n",
    "merge_id = []\n",
    "\n",
    "for x in hwy_sort['merge']:\n",
    "    if x == 0:\n",
    "        unique_id = unique_id + 1\n",
    "    merge_id.append(unique_id)\n",
    "\n",
    "hwy_sort['diss_id'] = merge_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_routes = hwy_sort.groupby(['PMRouteID_Fix','diss_id']).agg({'begPM_Fix': 'min', 'endPM_Fix': 'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "SlidingDist = 2\n",
    "SInterval = 1\n",
    "\n",
    "# Create walk through each dissolved road. Information about windows is recorded in lists that\n",
    "# are later processed into dataframe\n",
    "seg_ID_lst = []\n",
    "road_diss_lst = []\n",
    "RID_lst = []\n",
    "BMP_lst = []\n",
    "EMP_lst = []\n",
    "BMP_full = []\n",
    "EMP_full = []\n",
    "\n",
    "# Index used to ID each window\n",
    "i = 1\n",
    "\n",
    "for index, row in agg_routes.iterrows():\n",
    "    lengthTemp = row['endPM_Fix'] - row['begPM_Fix']\n",
    "    BMP = row['begPM_Fix']\n",
    "    EMP = row['endPM_Fix']\n",
    "\n",
    "    SlidePostStart = BMP\n",
    "    SlidePostEnd = BMP + SlidingDist\n",
    "\n",
    "    # If segment is less than the analysis window\n",
    "    if lengthTemp <= SlidingDist:\n",
    "        seg_ID_lst.append(i)\n",
    "        road_diss_lst.append(row['diss_id'])\n",
    "        RID_lst.append(row['PMRouteID_Fix'])\n",
    "        BMP_lst.append(row['begPM_Fix'])\n",
    "        EMP_lst.append(row['endPM_Fix'])\n",
    "        BMP_full.append(row['begPM_Fix'])\n",
    "        EMP_full.append(row['endPM_Fix'])\n",
    "        i = i + 1\n",
    "\n",
    "    # If segment is greater than the analysis window but less than the sliding distance plus analysis interval\n",
    "    # Creates one window from BMP and one working backwards from end of the segment\n",
    "    elif (lengthTemp > SlidingDist) and (lengthTemp <= (SlidingDist + SInterval)):\n",
    "        seg_ID_lst.append(i)\n",
    "        road_diss_lst.append(row['diss_id'])\n",
    "        RID_lst.append(row['PMRouteID_Fix'])\n",
    "        BMP_lst.append(row['begPM_Fix'])\n",
    "        EMP_lst.append(SlidePostEnd)\n",
    "        BMP_full.append(row['begPM_Fix'])\n",
    "        EMP_full.append(row['endPM_Fix'])\n",
    "        i = i + 1\n",
    "\n",
    "        SlidePostStart = SlidePostStart + SInterval\n",
    "        seg_ID_lst.append(i)\n",
    "        road_diss_lst.append(row['diss_id'])\n",
    "        RID_lst.append(row['PMRouteID_Fix'])\n",
    "        BMP_lst.append(row['endPM_Fix'] - SlidingDist)\n",
    "        EMP_lst.append(row['endPM_Fix'])\n",
    "        BMP_full.append(row['begPM_Fix'])\n",
    "        EMP_full.append(row['endPM_Fix'])\n",
    "        i = i + 1\n",
    "\n",
    "    # If the segment is fits at least two analysis windows offset by the sliding distance\n",
    "    # Create sliding windows while distance and end with last segment working backwards from end of segment\n",
    "    elif lengthTemp > (SlidingDist + SInterval):\n",
    "        while SlidePostEnd < EMP:\n",
    "            seg_ID_lst.append(i)\n",
    "            road_diss_lst.append(row['diss_id'])\n",
    "            RID_lst.append(row['PMRouteID_Fix'])\n",
    "            BMP_lst.append(SlidePostStart)\n",
    "            EMP_lst.append(SlidePostEnd)\n",
    "            BMP_full.append(row['begPM_Fix'])\n",
    "            EMP_full.append(row['endPM_Fix'])\n",
    "            i = i + 1\n",
    "            SlidePostStart = SlidePostStart + SInterval\n",
    "            SlidePostEnd = SlidePostEnd + SInterval\n",
    "\n",
    "        seg_ID_lst.append(i)\n",
    "        road_diss_lst.append(row['diss_id'])\n",
    "        RID_lst.append(row['PMRouteID_Fix'])\n",
    "        BMP_lst.append(row['endPM_Fix'] - SlidingDist)\n",
    "        EMP_lst.append(row['endPM_Fix'])\n",
    "        BMP_full.append(row['begPM_Fix'])\n",
    "        EMP_full.append(row['endPM_Fix'])\n",
    "        i = i + 1\n",
    "\n",
    "# Combine lists into a dataframe\n",
    "d = {'Seg_ID': seg_ID_lst, 'PMRouteID_Fix': RID_lst, 'begPM_Fix': BMP_lst, 'endPM_Fix': EMP_lst, 'diss_id': road_diss_lst, \\\n",
    "        'BMP_full': BMP_full, 'EMP_full': EMP_full}\n",
    "sl_winds = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sl_winds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "intx['mp'] = intx[['begPM_Fix','endPM_Fix']].mean(axis = 1)\n",
    "ramp['mp'] = ramp[['begPM_Fix','endPM_Fix']].mean(axis = 1)\n",
    "hwy['start'] = hwy['begPM_Fix']\n",
    "hwy['end'] = hwy['endPM_Fix']\n",
    "sl_winds['length'] = (sl_winds['endPM_Fix'] - sl_winds['begPM_Fix'])/SlidingDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_intx = sl_winds.merge(intx[['PMRouteID_Fix','mp','intx_points']], how = 'left')\n",
    "sl_intx = sl_intx[(sl_intx['mp'] >= sl_intx['begPM_Fix']) & (sl_intx['mp'] <= sl_intx['endPM_Fix'])]\n",
    "\n",
    "sl_ramp = sl_winds.merge(ramp[['PMRouteID_Fix','mp','ramp_points']], how = 'left')\n",
    "sl_ramp = sl_ramp[(sl_ramp['mp'] >= sl_ramp['begPM_Fix']) & (sl_ramp['mp'] <= sl_ramp['endPM_Fix'])]\n",
    "\n",
    "sl_hwy = sl_winds.merge(hwy[['PMRouteID_Fix','start','end','road_points']], how = 'left')\n",
    "sl_hwy['road_points_scale'] = 0\n",
    "sl_hwy['road_points_scale'][(sl_hwy['start'] <= sl_hwy['begPM_Fix']) & (sl_hwy['end'] >= sl_hwy['endPM_Fix'])] = sl_hwy['road_points'] * sl_hwy['length']\n",
    "sl_hwy['road_points_scale'][(sl_hwy['start'] >= sl_hwy['begPM_Fix']) & (sl_hwy['end'] >= sl_hwy['endPM_Fix'])] = sl_hwy['road_points'] * (sl_hwy['endPM_Fix'] - sl_hwy['start'])\n",
    "sl_hwy['road_points_scale'][(sl_hwy['start'] <= sl_hwy['begPM_Fix']) & (sl_hwy['end'] <= sl_hwy['endPM_Fix'])] = sl_hwy['road_points'] * (sl_hwy['end'] - sl_hwy['begPM_Fix'])\n",
    "sl_hwy['road_points_scale'][(sl_hwy['end'] <= sl_hwy['begPM_Fix']) | (sl_hwy['start'] >= sl_hwy['endPM_Fix'])] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_winds_wintx = sl_winds.merge(sl_intx.groupby('Seg_ID')['intx_points'].sum(), on = 'Seg_ID', how = 'left').fillna(0)\n",
    "sl_winds_wir = sl_winds_wintx.merge(sl_ramp.groupby('Seg_ID')['ramp_points'].sum(), on = 'Seg_ID', how = 'left').fillna(0)\n",
    "sl_winds_wirh = sl_winds_wir.merge(sl_hwy.groupby('Seg_ID')['road_points_scale'].sum(), on = 'Seg_ID', how = 'left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_winds_wirh['score'] = sl_winds_wirh[['intx_points','ramp_points','road_points_scale']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "      ... \n",
       "720    0.0\n",
       "721    0.0\n",
       "722    0.0\n",
       "723    0.0\n",
       "724    0.0\n",
       "Name: intx_points, Length: 725, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
